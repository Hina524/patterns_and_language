# Name of your Pattern-matching Tool
https://github.com/Hina524/patterns_and_language
# Group members

| å­¦ç±ç•ªå·     | æ°å           | è²¢çŒ®å†…å®¹                                          |
| -------- | ------------ | --------------------------------------------- |
| s1310141 | Hina Konishi | 70% (main programmer, test, report, analysis) |
| s1290116 | Tsubasa Sato | 30% (analysis)                                |
# 1. Tool description
## Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å…¨ä½“ã®ç›®çš„

ã“ã®Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€**è‹±èªå­¦ç¿’è€…ã€è¨€èªå‡¦ç†å­¦ç¿’è€…ã®åŒ…æ‹¬çš„ãªè¨€èªç¿’å¾—æ”¯æ´ã‚·ã‚¹ãƒ†ãƒ **ã¨ã—ã¦è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚
## 3ã¤ã®ä¸»è¦æ©Ÿèƒ½

### 1. English Grammar Analyzeræ©Ÿèƒ½

è‹±èªã®æ–‡ç« ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€ãã®æ–‡ç« ã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«**æ–‡æ³•çš„ã«åˆ†æ**ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚
- **éå»å½¢å¤‰æ›**: æ–‡ç« ä¸­ã®å‹•è©ã‚’è‡ªå‹•çš„ã«éå»å½¢ã«å¤‰æ›
- **æ–‡ã‚¿ã‚¤ãƒ—åˆ¤å®š**: ãã®æ–‡ãŒ Simpleï¼ˆå˜æ–‡ï¼‰ã€Compoundï¼ˆé‡æ–‡ï¼‰ã€Complexï¼ˆè¤‡æ–‡ï¼‰ã®ã©ã‚Œã‹ã‚’åˆ¤å®š
- **å‰ç½®è©å¥æŠ½å‡º**: æ–‡ç« ã®ä¸­ã«ã‚ã‚‹å‰ç½®è©å¥ï¼ˆ"in the library"ãªã©ï¼‰ã‚’è‡ªå‹•ã§è¦‹ã¤ã‘å‡ºã™
#### æ©Ÿèƒ½ç›®çš„
- **åŒ…æ‹¬çš„æ–‡æ³•åˆ†æ**: å…¥åŠ›ã•ã‚ŒãŸè‹±èªæ–‡ã®å¤šé¢çš„æ–‡æ³•æ§‹é€ è§£æ
- **æ™‚åˆ¶å¤‰æ›å®Ÿè·µ**: ç¾åœ¨å½¢ã‹ã‚‰éå»å½¢ã¸ã®å¤‰æ›ã‚’é€šã˜ãŸå‹•è©æ´»ç”¨å­¦ç¿’
- **æ–‡å‹ç†è§£ä¿ƒé€²**: Simpleã€Compoundã€Complexæ–‡ã®æ§‹é€ çš„é•ã„ã®ä½“é¨“å­¦ç¿’
- **å‰ç½®è©å¥èªè­˜**: è‹±èªç‰¹æœ‰ã®å‰ç½®è©æ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç¿’å¾—æ”¯æ´
### 2. Template Sentence Generatoræ©Ÿèƒ½

è‹±èªã®**æ–‡ç« ä½œæˆã‚’æ”¯æ´**ã™ã‚‹ãŸã‚ã«ã€ç”¨é€”åˆ¥ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ–‡ã‚’æä¾›ã—ã¦ãã‚Œã‚‹ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚ä»¥ä¸‹ã®4ã¤ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæ–‡ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ç”Ÿæˆã—ã¾ã™ã€‚
- **Topic Sentence**: æ–‡ç« ã®å°å…¥éƒ¨åˆ†ã§ä½¿ãˆã‚‹æ–‡
- **Sensory Details**: äº”æ„Ÿã‚’ä½¿ã£ãŸæå†™æ–‡
- **Spatial Details**: å ´æ‰€ã‚„ä½ç½®é–¢ä¿‚ã‚’è¡¨ã™æ–‡
- **Concluding Sentence**: æ–‡ç« ã®çµè«–éƒ¨åˆ†ã§ä½¿ãˆã‚‹æ–‡
#### **æ©Ÿèƒ½ç›®çš„**
- **ãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°æ”¯æ´**: æå†™æ–‡ã®ä½“ç³»çš„æ§‹æˆæ–¹æ³•ã®ç¿’å¾—
- **èªå½™æ‹¡å¼µä¿ƒé€²**: ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æä¾›
- **å‰µä½œã‚¤ãƒ³ã‚¹ãƒ”ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³**: ãƒ©ã‚¤ãƒ†ã‚£ãƒ³ã‚°ãƒ–ãƒ­ãƒƒã‚¯è§£æ¶ˆã®ã‚¢ã‚¤ãƒ‡ã‚¢ç”Ÿæˆ
### 3. Pattern Finderæ©Ÿèƒ½

æ‰‹å‹•å…¥åŠ›ã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§è¤‡æ•°ã®è‹±èªãƒ†ã‚­ã‚¹ãƒˆã‚’æ¯”è¼ƒã—ã¦ã€ãã‚Œã‚‰ã®é–“ã«ã‚ã‚‹**å…±é€šã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚„è¡¨ç¾**ã‚’ä»¥ä¸‹ã®**4æ®µéšã®åˆ†æãƒ¬ãƒ™ãƒ«**ã§è‡ªå‹•çš„ã«è¦‹ã¤ã‘å‡ºã™ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚
  - Level 1: å˜èªãƒ¬ãƒ™ãƒ«ã®å…±é€šãƒ‘ã‚¿ãƒ¼ãƒ³
  - Level 2: å˜èª + å“è©ã‚¿ã‚°ã®å…±é€šãƒ‘ã‚¿ãƒ¼ãƒ³  
  - Level 3: å˜èª + å¥ã‚¿ã‚¤ãƒ—ã®å…±é€šãƒ‘ã‚¿ãƒ¼ãƒ³
  - Level 4: å˜èª + å“è© + å¥ã‚¿ã‚¤ãƒ—ã®åŒ…æ‹¬çš„åˆ†æ
#### **æ©Ÿèƒ½ç›®çš„**
- **è¨€èªãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜**: è¤‡æ•°ãƒ†ã‚­ã‚¹ãƒˆé–“ã®å…±é€šæ§‹é€ ãƒ»è¡¨ç¾ã®ç™ºè¦‹
- **æ¯”è¼ƒè¨€èªå­¦ç¿’**: é¡ä¼¼æ–‡æ§‹é€ ã®å®¢è¦³çš„åˆ†æã«ã‚ˆã‚‹ç†è§£æ·±åŒ–
- **èªå­¦ç ”ç©¶æ”¯æ´**: corpus linguisticsã®åŸºç¤çš„æ‰‹æ³•ã®å®Ÿè·µ
- **å¤šå±¤åˆ†æä½“é¨“**: èªå½™â†’å“è©â†’å¥æ§‹é€ ã®æ®µéšçš„è¨€èªç†è§£
# 2. Language analysis
## 1. English Grammar Analyzeræ©Ÿèƒ½
### Analysis
#### 1. æ™‚åˆ¶å¤‰æ›
```python
def convert_to_past_tense(self, text: str) -> str:
    doc = self.nlp(text)
    tokens = []
    for token in doc:
        if self._should_convert_to_past(token, doc):
            past_form = self._get_past_form(token)
            tokens.append(past_form)
        else:
            tokens.append(token.text)
```

**è¨€èªç†è«–çš„åŸºç›¤:**
- **spaCyä¾å­˜é–¢ä¿‚è§£æ**: æ–‡æ§‹é€ ã®æ­£ç¢ºãªæŠŠæ¡ã«ã‚ˆã‚‹æ–‡è„ˆé©å¿œå‹å‹•è©å¤‰æ›
- **è‹±èªå‹•è©æ´»ç”¨ä½“ç³»**: è¦å‰‡å‹•è©ï¼ˆ-edä»˜åŠ ï¼‰ãƒ»ä¸è¦å‰‡å‹•è©ï¼ˆèªå¹¹å¤‰åŒ–ï¼‰ãƒ»åŠ©å‹•è©ã®åŒ…æ‹¬çš„å‡¦ç†
- **æ™‚åˆ¶ä¸€è‡´åŸç†**: æ–‡å…¨ä½“ã«ãŠã‘ã‚‹æ™‚åˆ¶ã®çµ±ä¸€æ€§ç¶­æŒ
- **é«˜ç²¾åº¦å½¢æ…‹è«–è§£æ**: èªå¹¹æŠ½å‡ºâ†’æ´»ç”¨èªå°¾å‡¦ç†â†’ä¸è¦å‰‡å‹•è©è¾æ›¸ç…§åˆ

**å®Ÿè£…ã®ç‰¹å¾´:**
1. **ä¸è¦å‰‡å‹•è©è¾æ›¸ï¼ˆ80èªä»¥ä¸Šï¼‰**:
   - åŸºæœ¬å‹•è©: goâ†’went, comeâ†’came, seeâ†’saw, makeâ†’made
   - beå‹•è©: isâ†’was, areâ†’were, amâ†’was
   - ç‰¹æ®Šå‹•è©: shineâ†’shone, swimâ†’swam, flyâ†’flew
   - åŠ©å‹•è©: canâ†’could, willâ†’would, mayâ†’might

2. **å”èª¿å‹•è©å‡¦ç†**:
   - ç­‰ä½æ¥ç¶šè©ã§çµã°ã‚ŒãŸå‹•è©ã®ä¸€æ‹¬å¤‰æ›
   - ä¾‹: "They swim, run, and fly" â†’ "They swam, ran, and flew"
   - spaCyã®ã‚¿ã‚°ä»˜ã‘ã‚¨ãƒ©ãƒ¼ï¼ˆVBNèª¤èªè­˜ï¼‰ã¸ã®å¯¾å¿œ

3. **åŠ©å‹•è©æ§‹é€ ã®å‡¦ç†**:
   - Modal auxiliary (MD)ã®å¤‰æ›: canâ†’could, willâ†’would
   - åŠ©å‹•è©å¾Œã®å‹•è©ã¯åŸå½¢ç¶­æŒ: "can go" â†’ "could go"
   - be/haveå‹•è©ã®é©åˆ‡ãªå¤‰æ›: hasâ†’had, areâ†’were

4. **é€²è¡Œå½¢ã®ä¿æŒ**:
   - beå‹•è©ã®ã¿å¤‰æ›ã€-ingå½¢ã¯ç¶­æŒ
   - ä¾‹: "We are walking" â†’ "We were walking"
   - ä¾å­˜é–¢ä¿‚è§£æã«ã‚ˆã‚‹é€²è¡Œå½¢æ§‹é€ ã®æ­£ç¢ºãªè­˜åˆ¥

5. **è¦å‰‡å‹•è©ã®ç²¾å¯†ãªæ´»ç”¨ãƒ«ãƒ¼ãƒ«**:
   - -eçµ‚ã‚ã‚Š: likeâ†’liked
   - å­éŸ³+y: studyâ†’studied  
   - æ¯éŸ³+y: playâ†’playedï¼ˆplayyedèª¤ã‚Šã‚’é˜²æ­¢ï¼‰
   - CVC pattern: stopâ†’stopped
   - ãã®ä»–: workâ†’worked

#### 2. æ–‡æ§‹é€ åˆ†æ
**ç†è«–çš„åŸºç›¤: Dependency Grammar + Syntactic Parsing**

```python
def get_sentence_type(self, text: str) -> str:
    doc = self.nlp(text)
    subordinators = {'after', 'although', 'as', 'because', 'before'...}
    
    # å¾“å±ç¯€æ¤œå‡º
    for token in doc:
        if token.text.lower() in subordinators:
            if any(child.dep_ in ['ccomp', 'advcl', 'acl'] 
                   for child in token.head.children):
                return 'complex'
```

1. **Simple Sentenceï¼ˆå˜æ–‡ï¼‰**: å˜ä¸€ä¸»èª+å‹•è©æ§‹é€ 
2. **Compound Sentenceï¼ˆé‡æ–‡ï¼‰**: ç­‰ä½æ¥ç¶šè©ã«ã‚ˆã‚‹ç‹¬ç«‹ç¯€çµåˆ
3. **Complex Sentenceï¼ˆè¤‡æ–‡ï¼‰**: å¾“å±æ¥ç¶šè©ã«ã‚ˆã‚‹ä¸»ç¯€+å¾“å±ç¯€æ§‹é€ 

**spaCyä¾å­˜é–¢ä¿‚ãƒ©ãƒ™ãƒ«æ´»ç”¨:**
- `ccomp`: ç¯€è£œèª (clausal complement)
- `advcl`: å‰¯è©ç¯€ (adverbial clause modifier)  
- `acl`: é–¢ä¿‚ç¯€ (clausal modifier of noun)

#### 3. å‰ç½®è©å¥æŠ½å‡º
**ä¾å­˜é–¢ä¿‚è§£æã«ã‚ˆã‚‹é«˜ç²¾åº¦æŠ½å‡º:**
```python
def get_prepositional_phrases(self, text: str) -> List[str]:
    doc = self.nlp(text)
    for token in doc:
        if token.pos_ == 'ADP':  # å‰ç½®è©æ¤œå‡º
            for child in token.children:
                if child.dep_ == 'pobj':  # å‰ç½®è©ã®ç›®çš„èª
                    phrase_tokens.extend(self._get_noun_phrase_tokens(child, doc))
```

- **æ§‹æ–‡è§£æ**: å‰ç½®è© + ä¾å­˜é–¢ä¿‚ã«ã‚ˆã‚‹ç›®çš„èªç‰¹å®š
- **å¥å¢ƒç•Œèªè­˜**: ä¿®é£¾èªãƒ»é™å®šè©ã®åŒ…æ‹¬çš„æ¤œå‡º
- **ãƒã‚¹ãƒˆæ§‹é€ **: "in the garden behind the house near the river"

### Algorithm Diagram

``` mermaid
flowchart TD
    A[å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆ] --> B[spaCy NLPå‡¦ç†]
    B --> C[ä¾å­˜é–¢ä¿‚è§£æå®Œäº†]
    C --> D[æ™‚åˆ¶å¤‰æ›å‡¦ç†]
    C --> E[æ–‡æ§‹é€ åˆ†æ]
    C --> F[å‰ç½®è©å¥æŠ½å‡º]
    
    D --> D1[å‹•è©ãƒ»åŠ©å‹•è©è­˜åˆ¥]
    D1 --> D2[å¤‰æ›åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯]
    D2 --> D3{åŠ©å‹•è©åˆ¤å®š}
    D3 -->|Modal MD| D3A[canâ†’couldç­‰å¤‰æ›]
    D3 -->|be/have| D3B[isâ†’wasç­‰å¤‰æ›]
    D3 -->|No| D4{é€²è¡Œå½¢åˆ¤å®š}
    D4 -->|Yes| D4A[beå‹•è©ã®ã¿å¤‰æ›<br/>-ingå½¢ç¶­æŒ]
    D4 -->|No| D5{å”èª¿æ§‹é€ ?}
    D5 -->|Yes| D6[å”èª¿å‹•è©å¤‰æ›]
    D5 -->|No| D7[å˜ä¸€å‹•è©å¤‰æ›]
    
    D3A --> G[Flask API Response]
    D3B --> G
    D4A --> G
    
    D6 --> D8{ä¸è¦å‰‡å‹•è©?}
    D7 --> D8
    D8 -->|Yes| D9[80+å‹•è©è¾æ›¸æ¤œç´¢<br/>swimâ†’swamç­‰]
    D8 -->|No| D10[è¦å‰‡å‹•è©ãƒ«ãƒ¼ãƒ«]
    D10 --> D10A{èªå°¾åˆ¤å®š}
    D10A -->|e| D10B[+d: likeâ†’liked]
    D10A -->|å­éŸ³+y| D10C[yâ†’ied: studyâ†’studied]
    D10A -->|æ¯éŸ³+y| D10D[+ed: playâ†’played]
    D10A -->|CVC| D10E[é‡è¤‡+ed: stopâ†’stopped]
    D10A -->|ä»–| D10F[+ed: workâ†’worked]
    
    D9 --> G
    D10B --> G
    D10C --> G
    D10D --> G
    D10E --> G
    D10F --> G
    
    E --> E1[å¾“å±æ¥ç¶šè©æ¤œç´¢]
    E1 --> E2{ä¾å­˜é–¢ä¿‚ãƒ©ãƒ™ãƒ«ç¢ºèª}
    E2 -->|ccomp/advcl/acl| E3[Complexåˆ¤å®š]
    E2 -->|No| E4[ç­‰ä½æ¥ç¶šè©åˆ†æ]
    E4 --> E5{è¤‡æ•°ä¸»å‹•è©?}
    E5 -->|Yes| E6[Compoundåˆ¤å®š]
    E5 -->|No| E7[Simpleåˆ¤å®š]
    
    F --> F1[ADPå“è©æ¤œå‡º]
    F1 --> F2[pobjä¾å­˜é–¢ä¿‚]
    F2 --> F3[åè©å¥æ‹¡å¼µ]
    F3 --> F4[å¥å¢ƒç•Œç¢ºå®š]
    
    E3 --> G
    E6 --> G
    E7 --> G
    F4 --> G
    G --> H[JSONçµæœè¿”å´]
    H --> I[ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰è¡¨ç¤º]
```
Fig. 1: [English Grammar Analyzeræ©Ÿèƒ½ã®Algorithm Diagram]
## 2. Template Sentence Generatoræ©Ÿèƒ½
### Analysis

#### æ–‡ç« æ§‹é€ ç†è«–
**Academic Writing Theory + Paragraph Development Model**
```javascript
const topicSentences = [10å€‹ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ];      // å°å…¥éƒ¨
const sensoryDetails = [10å€‹ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ];      // æ„Ÿè¦šæå†™
const spatialDetails = [10å€‹ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ];      // ç©ºé–“æå†™
const concludingSentences = [9å€‹ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ];   // çµè«–éƒ¨
```

**è¨€èªå­¦çš„åˆ†æåŸºç›¤:**

1. **Topic Sentence Analysisï¼ˆä¸»é¡Œæ–‡åˆ†æï¼‰**
   - **Discourse Markers**: "I want to describe", "Today, I will"
   - **Thematic Structure**: ä¸»é¡Œæç¤ºâ†’è©³ç´°å±•é–‹ã®äºˆå‘Šæ©Ÿèƒ½

2. **Sensory Description Frameworkï¼ˆæ„Ÿè¦šæå†™æ çµ„ã¿ï¼‰**
   ```javascript
   'It looks ___ and ___.',
   'You can hear ___, especially when ___.',
   'It smells like ___, and that reminds me of ___.'
   ```
   - **äº”æ„Ÿã‚«ãƒ†ã‚´ãƒªãƒ¼åŒ–**: è¦–è¦šãƒ»è´è¦šãƒ»å—…è¦šãƒ»è§¦è¦šãƒ»å‘³è¦šã®ä½“ç³»çš„é…ç½®
   - **Cognitive Linguistics**: æ„Ÿè¦šä½“é¨“â†’è¨€èªè¡¨ç¾ã®ãƒãƒƒãƒ”ãƒ³ã‚°

3. **Spatial Coherence Theoryï¼ˆç©ºé–“çš„çµæŸç†è«–ï¼‰**
   ```javascript
   'It is located near ___.',
   'Around it, there are ___ and ___.',
   'Inside, you can find ___.'
   ```
   - **Spatial Deixis**: ä½ç½®é–¢ä¿‚ã‚’ç¤ºã™æŒ‡ç¤ºè¡¨ç¾
   - **Topological Relations**: near, around, insideç­‰ã®ç©ºé–“å‰ç½®è©
#### **ãƒ©ãƒ³ãƒ€ãƒ åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ **
```javascript
function showRandomTemplate(list, label) {
    const idx = Math.floor(Math.random() * list.length);
    templateOutput.innerText = `${label}:\n${list[idx]}`;
}
```
- **Uniform Distribution**: å„ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®ç­‰ç¢ºç‡é¸æŠ
- **Cognitive Load Theory**: äºˆæ¸¬ä¸å¯èƒ½æ€§ã«ã‚ˆã‚‹å‰µé€ çš„æ€è€ƒä¿ƒé€²
### Algorithm Diagram
``` mermaid
flowchart TD
    A[ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒã‚«ãƒ†ã‚´ãƒªãƒ¼é¸æŠ] --> B{ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¤å®š}
    
    B -->|Topic Sentence| C[topicSentencesé…åˆ—]
    B -->|Sensory Details| D[sensoryDetailsé…åˆ—]
    B -->|Spatial Details| E[spatialDetailsé…åˆ—]
    B -->|Concluding| F[concludingSentencesé…åˆ—]
    
    C --> G[Math.randomç”Ÿæˆ]
    D --> G
    E --> G
    F --> G
    
    G --> H[é…åˆ—é•·ã¨ã®ä¹—ç®—]
    H --> I[Math.flooræ•´æ•°åŒ–]
    I --> J[ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ±ºå®š]
    
    J --> K[å¯¾å¿œãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå–å¾—]
    K --> L[ãƒ©ãƒ™ãƒ«ä»˜åŠ ]
    L --> M[çµæœè¡¨ç¤º]
    
    subgraph "æ–‡ç« æ§‹é€ ç†è«–"
        N[Topic Introduction]
        O[Sensory Elaboration]
        P[Spatial Organization]
        Q[Conclusion/Reflection]
        N --> O --> P --> Q
    end
    
    C -.-> N
    D -.-> O
    E -.-> P
    F -.-> Q
```
Fig. 2: [Template Sentence Generatoræ©Ÿèƒ½ã®Algorithm Diagram]
## 3. Pattern Finderæ©Ÿèƒ½
### Analysis
#### å¤šå±¤è¨€èªåˆ†æã‚·ã‚¹ãƒ†ãƒ 
**spaCy + Dependency Grammar + Phrase Structure Grammar**

**Level 1: Lexical Analysisï¼ˆèªå½™åˆ†æï¼‰**
```python
return [token.text for token in doc if not token.is_space]
```
- **Tokenization Theory**: èªå¢ƒç•Œèªè­˜ã«ã‚ˆã‚‹æœ€å°è¨€èªå˜ä½åˆ†å‰²

**Level 2: Morpho-syntactic Analysisï¼ˆå½¢æ…‹çµ±èªåˆ†æï¼‰**
```python
return [(token.text, token.pos_) for token in doc if not token.is_space]
```
- **Penn Treebank Tagset**: DT, NN, VB, INç­‰ã®æ¨™æº–å“è©ä½“ç³»
- **Part-of-Speech Tagging**: çµ±è¨ˆçš„è¨€èªãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹å“è©è‡ªå‹•ä»˜ä¸

**Level 3: Phrase Structure Analysisï¼ˆå¥æ§‹é€ åˆ†æï¼‰**
```python
# å¥èª­ç‚¹é™¤å¤–ã«ã‚ˆã‚‹ç´”ç²‹å¥æ§‹é€ åˆ†æ
if token.is_space or token.pos_ == 'PUNCT':
    continue
phrase_type = self.get_phrase_type(token, doc, phrase_map)
```

**ç†è«–çš„åŸºç›¤: X-bar Theory + Dependency Grammar**
#### **å¥æ§‹é€ æ¤œå‡ºã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ **
```python
def _build_phrase_map(self, doc):
    # Step 0: ã‚«ã‚¹ã‚¿ãƒ ä¿®æ­£ã«ã‚ˆã‚‹ç²¾åº¦å‘ä¸Š
    self._apply_custom_corrections(doc, phrase_map)
    
    # Step 1: spaCy noun_chunksã«ã‚ˆã‚‹åè©å¥æ¤œå‡º
    for chunk in doc.noun_chunks:
        for i in range(chunk.start, chunk.end):
            phrase_map[i] = 'NP'
    
    # Step 2: ä¸å®šè©å¥æ¤œå‡ºï¼ˆå‹•è©å¥ã‚ˆã‚Šå…ˆã«å‡¦ç†ï¼‰
    for token in doc:
        if self._is_infinitive_marker(token, doc):
            inf_tokens = self._get_infinitive_phrase_tokens(token, doc)
            for tok_idx in inf_tokens:
                phrase_map[tok_idx] = 'INF-P'
    
    # Step 3: ä¾å­˜é–¢ä¿‚è§£æã«ã‚ˆã‚‹å‹•è©å¥æ¤œå‡º
    if token.pos_ in ['VERB', 'AUX'] and token.i not in phrase_map:
        vp_tokens = self._get_verb_phrase_tokens(token, doc)
```

**ã‚«ã‚¹ã‚¿ãƒ ä¿®æ­£æ©Ÿèƒ½:**
```python
def _apply_custom_corrections(self, doc, phrase_map):
    """spaCyã®ã‚¿ã‚°ä»˜ã‘ç²¾åº¦å•é¡Œã¸ã®å¯¾å‡¦"""
    for token in doc:
        # å‹•åè©ä¸»èªã®ä¿®æ­£ï¼ˆSwimming[PROPN] â†’ Swimming[VP]ï¼‰
        if (token.pos_ == 'PROPN' and 
            token.tag_ == 'NNP' and 
            token.dep_ == 'nsubj' and 
            token.text.lower().endswith('ing')):
            phrase_map[token.i] = 'VP'
        
        # æ™‚é–“è¡¨ç¾ã®çµ±ä¸€ï¼ˆtoday, nowç­‰ã‚’ADVPã«ï¼‰
        if self._is_time_expression(token, doc):
            phrase_map[token.i] = 'ADVP'
```

**ä¸å®šè©å¥æ¤œå‡º:**
```python
def _is_infinitive_marker(self, token, doc):
    """to + å‹•è©æ§‹é€ ã®è­˜åˆ¥"""
    if (token.pos_ == 'PART' and 
        token.tag_ == 'TO' and 
        token.text.lower() == 'to'):
        # å¾Œç¶šå‹•è©ãƒã‚§ãƒƒã‚¯
        if token.i + 1 < len(doc):
            next_token = doc[token.i + 1]
            if next_token.pos_ == 'VERB' and next_token.tag_ == 'VB':
                return True
```

**å‹•è©å¥å¢ƒç•Œæ¤œå‡º:**
```python
def _get_verb_phrase_tokens(self, verb, doc):
    # ä¾å­˜é–¢ä¿‚ãƒ©ãƒ™ãƒ«ã«ã‚ˆã‚‹å¥æ§‹æˆè¦ç´ ç‰¹å®š
    for child in verb.children:
        if child.dep_ in ['aux', 'auxpass', 'neg', 'prt']:
            vp_tokens.add(child.i)
```
#### **ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°ç†è«–**
**Sequence Alignment + N-gram Analysis**

```python
def find_common_patterns(self, token_sequences):
    # æœ€çŸ­ã‚·ãƒ¼ã‚±ãƒ³ã‚¹åŸºæº–ã«ã‚ˆã‚‹åŠ¹ç‡åŒ–
    base_idx = min(range(len(token_sequences)), 
                   key=lambda i: len(token_sequences[i][1]))
    
    # å…¨å¯èƒ½éƒ¨åˆ†åˆ—æ¢ç´¢
    for length in range(n, 0, -1):  # é•·ã„ãƒ‘ã‚¿ãƒ¼ãƒ³å„ªå…ˆ
        for start in range(n - length + 1):
            pattern = tuple(base_seq[start:start + length])
```

**è¨ˆç®—é‡æœ€é©åŒ–:**
- **Time Complexity**: O(nÂ²m) where n=sequence length, m=number of texts
- **Space Complexity**: O(nm) for pattern storage
### **ğŸ”¬ Level 4çµ±åˆåˆ†æã®è¤‡é›‘æ€§**

**Level 4: Multi-dimensional Analysisï¼ˆå¤šæ¬¡å…ƒçµ±åˆåˆ†æï¼‰**
```python
tokens.append((token.text, token.pos_, phrase_type))
```

**è¨€èªå­¦çš„æ„ç¾©:**
- **Morpho-syntactic Interface**: å½¢æ…‹è«–ã¨çµ±èªè«–ã®æ¥ç¶šç‚¹åˆ†æ
- **Feature Unification**: å“è©æƒ…å ±ã¨å¥æ§‹é€ æƒ…å ±ã®çµ±åˆ
- **Linguistic Annotation**: å¤šå±¤è¨€èªæƒ…å ±ã®åŒæ™‚è¡¨ç¾

**å¥èª­ç‚¹ã®ç†è«–çš„å‡¦ç†:**
```python
if token.pos_ == 'PUNCT':
    # Level 3: å¥æ§‹é€ åˆ†æã§ã¯é™¤å¤–
    continue
    # Level 4: POSã¯ä¿æŒã€å¥ã‚¿ã‚¤ãƒ—ã¯ç„¡åŠ¹åŒ–
    tokens.append((token.text, token.pos_, 'O'))
```

**ç†è«–çš„æ ¹æ‹ **: å¥èª­ç‚¹ã¯**éŸ»å¾‹å¢ƒç•Œï¼ˆProsodic Boundary**ã‚’ç¤ºã™ãŒã€**å¥æ§‹é€ ï¼ˆPhrase Structure**ã®æ§‹æˆè¦ç´ ã§ã¯ãªã„
### Algorithm Diagram
``` mermaid
flowchart TD
    A[è¤‡æ•°ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›] --> B[spaCy NLPå‡¦ç†]
    B --> C{åˆ†æãƒ¬ãƒ™ãƒ«é¸æŠ}
    
    C -->|Level 1| D1[Simple Tokenization]
    C -->|Level 2| D2[POS Tagging]
    C -->|Level 3| D3[Phrase Analysis]
    C -->|Level 4| D4[Combined Analysis]
    
    D3 --> E[å¥æ§‹é€ ãƒãƒƒãƒ—æ§‹ç¯‰]
    E --> E0[Step 0: ã‚«ã‚¹ã‚¿ãƒ ä¿®æ­£]
    E0 --> E0A[å‹•åè©ä¸»èªä¿®æ­£<br/>Swimming[PROPN]â†’[VP]]
    E0 --> E0B[æ™‚é–“è¡¨ç¾çµ±ä¸€<br/>today/nowâ†’[ADVP]]
    E0A --> E1[Step 1: åè©å¥æ¤œå‡º]
    E0B --> E1
    E1 --> E2[Step 2: ä¸å®šè©å¥æ¤œå‡º]
    E2 --> E3[Step 3: å‹•è©å¥æ¤œå‡º]
    E3 --> E4[Step 4: å‰ç½®è©å¥æ¤œå‡º]
    E4 --> E5[Step 5: å½¢å®¹è©å¥æ¤œå‡º]
    E5 --> E6[Step 6: å‰¯è©å¥æ¤œå‡º]
    E6 --> E7[Step 7: æ®‹ä½™ãƒˆãƒ¼ã‚¯ãƒ³åˆ†é¡]
    
    subgraph "ä¸å®šè©å¥æ¤œå‡ºè©³ç´°"
        INF1[to[PART]æ¤œå‡º]
        INF2[å¾Œç¶šå‹•è©ç¢ºèª]
        INF3[to + VBæ§‹é€ ]
        INF4[INF-Pã‚¿ã‚°ä»˜ä¸]
        INF1 --> INF2 --> INF3 --> INF4
    end
    
    E2 -.-> INF1
    
    subgraph "å‹•è©å¥æ¤œå‡ºè©³ç´°"
        F1[å‹•è©ãƒˆãƒ¼ã‚¯ãƒ³ç‰¹å®š]
        F2[ä¾å­˜é–¢ä¿‚è§£æ]
        F3[aux/neg/prtæ¤œå‡º]
        F4[VPå¢ƒç•Œç¢ºå®š]
        F1 --> F2 --> F3 --> F4
    end
    
    E3 -.-> F1
    
    D1 --> G[ãƒˆãƒ¼ã‚¯ãƒ³é…åˆ—ç”Ÿæˆ]
    D2 --> G
    E7 --> G
    D4 --> G
    
    G --> H[ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°]
    H --> H1[æœ€çŸ­ã‚·ãƒ¼ã‚±ãƒ³ã‚¹é¸æŠ]
    H1 --> H2[å…¨éƒ¨åˆ†åˆ—ç”Ÿæˆ]
    H2 --> H3[ãƒ‘ã‚¿ãƒ¼ãƒ³é »åº¦è¨ˆç®—]
    H3 --> H4[2ãƒ•ã‚¡ã‚¤ãƒ«ä»¥ä¸Šãƒ•ã‚£ãƒ«ã‚¿]
    H4 --> H5[é•·ã•ãƒ»é »åº¦ã‚½ãƒ¼ãƒˆ]
    
    H5 --> I[å…±é€šãƒ‘ã‚¿ãƒ¼ãƒ³å‡ºåŠ›]
    
    subgraph "è¨€èªç†è«–åŸºç›¤"
        J[Dependency Grammar]
        K[X-bar Theory]
        L[Penn Treebank]
        M[Phrase Structure Rules]
    end
    
    E -.-> J
    E -.-> K
    D2 -.-> L
    E -.-> M
```

Fig. 3: [Pattern Finderæ©Ÿèƒ½ã®Algorithm Diagram]
# 3. Software development
## ä½¿ç”¨æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯
### ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªãƒ»ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
- **Python 3.11**: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰å‡¦ç†ã€NLPè§£æã‚¨ãƒ³ã‚¸ãƒ³
- **JavaScript ES6+**: ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰å‹•çš„å‡¦ç†ã€éåŒæœŸAPIé€šä¿¡
- **HTML5**: ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯ãªæ§‹é€ åŒ–ãƒãƒ¼ã‚¯ã‚¢ãƒƒãƒ—
- **CSS3**: ãƒ¢ãƒ€ãƒ³ãªã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚°ã€ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³
### ä¸»è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
- **Flask 3.0.0**: è»½é‡Webãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
- **spaCy 3.8.5**: ç”£æ¥­æ¨™æº–NLPãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆEnglish Grammar Analyzer & Pattern Finder backendï¼‰
- **W3.CSS**: ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–CSSãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

## 1. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å…¨ä½“
### ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³
å…¨ã¦ã®åˆ©ç”¨å ´é¢ã«å¯¾å¿œã™ã‚‹ãŸã‚ã€PCã€ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã®ã©ã¡ã‚‰ã‹ã‚‰ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ã‚‚åˆ©ç”¨ãŒã§ãã‚‹ã‚ˆã†ã«ã—ã¦ã„ã¾ã™ã€‚
![[ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ 2025-08-02 22.06.12.png]]
Fig. 4: [PCã§èµ·å‹•ã—ãŸéš›ã®ç”»é¢]

![[ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ 2025-08-02 22.07.05.png|400]]
Fig. 5: [ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³ã§èµ·å‹•ã—ãŸéš›ã®ç”»é¢]
### ã‚¿ãƒ–ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
æœ¬ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯3ã¤ã®æ©Ÿèƒ½ãŒã‚ã‚‹ãŸã‚ã€MUIã‚’å‚è€ƒã«ã‚¿ãƒ–ã§æ©Ÿèƒ½åˆ‡ã‚Šæ›¿ãˆãŒã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã—ãŸã€‚
![[ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ 2025-08-02 19.12.52.png]]
Fig. 6: [ã‚¿ãƒ–ã®ç”»é¢]

```css
.tab-button {
    transition: all 0.3s ease;
    border-bottom: 2px solid transparent;
}
.tab-button.active {
    color: orange;
    border-bottom-color: orange;
}
```
## 2. English Grammar Analyzeræ©Ÿèƒ½
### æ©Ÿèƒ½åˆ©ç”¨ä¾‹
![[ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ 2025-08-02 22.06.12.png]]
Fig. 7: [English Grammar Analyzeræ©Ÿèƒ½ã®å…¥åŠ›ç”»é¢]
ä¸Šè¨˜ã®åˆæœŸç”»é¢ã®Inputéƒ¨åˆ†ã«è‹±æ–‡ã‚’å…¥åŠ›ã—ã€ã€ŒProcessã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨ã€
![[ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ 2025-08-02 22.24.46.png]]
Fig. 8: [English Grammar Analyzeræ©Ÿèƒ½ã®çµæœè¡¨ç¤ºç”»é¢]
ä¸Šè¨˜ç”»åƒã®ã‚ˆã†ã«çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

### å·¥å¤«ç‚¹
#### ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã‚¨ãƒªã‚¢ã®è¡Œæ•°ãŒå…¥åŠ›æ–‡ã®é•·ã•ã«åˆã‚ã›ã¦å¤‰å‹•ã™ã‚‹
å½“åˆã®å®Ÿè£…ã§ã¯ã€é•·æ–‡ã‚’å…¥åŠ›ã™ã‚‹ã¨æ–‡å­—ãŒè¦‹åˆ‡ã‚Œã¦ã—ã¾ã£ãŸãŸã‚ã€æ”¹å–„ã—ã¾ã—ãŸã€‚Fig. 8ã®ç”»åƒã¨æ¯”è¼ƒã—ã€Fig. 9ã§ã¯ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã‚¨ãƒªã‚¢ã®è¡Œæ•°ãŒå¢—ãˆã¦ã„ã‚‹ã“ã¨ãŒã‚ã‹ã‚Šã¾ã™ã€‚

```javascript
function autoResize(textarea) {
    textarea.style.height = 'auto';
    const minHeight = 3 * 24; // 3 lines
    const maxHeight = 10 * 24; // 10 lines
    const scrollHeight = textarea.scrollHeight;
    // å‹•çš„é«˜ã•èª¿æ•´ãƒ­ã‚¸ãƒƒã‚¯
}
```

![[ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ 2025-08-02 22.25.33.png]]
Fig. 9: [English Grammar Analyzeræ©Ÿèƒ½ã®å…¥åŠ›ã‚¨ãƒªã‚¢ã«é•·æ–‡ã‚’å…¥åŠ›ã—ãŸç”»åƒ]
## 3. Template Sentence Generatoræ©Ÿèƒ½
### æ©Ÿèƒ½åˆ©ç”¨ä¾‹
ã‚ªãƒ¬ãƒ³ã‚¸è‰²ã®ãƒœã‚¿ãƒ³ã®ã„ãšã‚Œã‹ã‚’é¸æŠã—ã¦æŠ¼ã™ã“ã¨ã§ã€é¸æŠã—ãŸã‚«ãƒ†ã‚´ãƒªã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒå‡ºåŠ›ã•ã‚Œã¾ã™ã€‚
![[ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ 2025-08-02 22.29.03.png]]
Fig. 10: [Template Sentence Generatoræ©Ÿèƒ½ã®çµæœè¡¨ç¤ºç”»é¢]
### å·¥å¤«ç‚¹
#### ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³
ã‚¹ãƒãƒ›ã‚µã‚¤ã‚ºï¼ˆ600pxä»¥ä¸‹ï¼‰ã§ã® Template Sentence Generator ãƒœã‚¿ãƒ³ã«ã¤ã„ã¦ã€PCã‚µã‚¤ã‚ºã§ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ(2Ã—2)ã«ã™ã‚‹ã¨æ–‡å­—ãŒæ½°ã‚Œã¦ã—ã¾ã†ã®ã§ã€ç¸¦ä¸€åˆ—ã®ä¸­å¤®æƒãˆã«ã—ã¾ã—ãŸã€‚
``` css
/* Template Sentence Generatorã®ãƒœã‚¿ãƒ³ä¸­å¤®å¯„ã› */
#templateTab .w3-row-padding {
	text-align: center;
	display: flex;
	flex-direction: column;
	align-items: center;
	gap: 8px;
}

#templateTab .w3-col {
	display: block;
	float: none;
	width: auto;
	max-width: 280px;
}

#templateTab .w3-button-orange {
	margin: 0 auto;
	display: block;
	width: auto;
	min-width: 200px;
	max-width: 280px;
}
```

![[ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ 2025-08-02 22.48.07.png|400]]
Fig. 11: [Template Sentence Generatoræ©Ÿèƒ½ã®ã‚¹ãƒãƒ›ã‚µã‚¤ã‚ºã®ç”»é¢]
## 4. Pattern Finderæ©Ÿèƒ½
### æ©Ÿèƒ½åˆ©ç”¨ä¾‹
æœ€åˆã«ã€ŒManual Text Inputã€ï¼ˆæ‰‹å…¥åŠ›ï¼‰ã‹ã€ŒUpload Text Filesã€ã‚’é¸æŠã—ã¾ã™ã€‚
![[ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ 2025-08-02 22.53.40.png]]
Fig. 12: [Pattern Finderæ©Ÿèƒ½ã®åˆæœŸç”»é¢]
#### ã€ŒManual Text Inputã€ã‚’é¸æŠã—ãŸå ´åˆ
ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ãŸã‚ã¨ã€Levelã‚’é¸æŠã—ã€Processã‚’æŠ¼ã—ã¾ã™ã€‚ãã†ã™ã‚‹ã¨ã€çµæœãŒä»¥ä¸‹ã®ã‚ˆã†ã«å‡ºåŠ›ã•ã‚Œã¾ã™ã€‚ï¼“ç¨®é¡ä»¥ä¸Šã®ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†æã™ã‚‹éš›ã¯ã€ã€ŒAdd Textã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã‚¨ãƒªã‚¢ãŒå¢—ãˆã€ã•ã‚‰ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚
![[ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ 2025-08-02 22.55.56.png]]
Fig. 13: [Pattern Finderæ©Ÿèƒ½ã§Manual Text Inputã‚’é¸æŠã—ãŸå ´åˆã®çµæœç”»é¢]
#### ã€ŒUpload Text Filesã€ã‚’é¸æŠã—ãŸå ´åˆ
ã“ã®å ´åˆã€ã¾ãšFig. 14ã®ã‚ˆã†ãªç”»é¢ã«ç§»å‹•ã—ã¾ã™ã€‚
- æ å†…ã«ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ—ã‚’ã™ã‚‹
- Select Text Filesãƒœã‚¿ãƒ³ã‚’æŠ¼ã™
ã®ã„ãšã‚Œã‹ã®æ–¹æ³•ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã¯.txtãƒ•ã‚¡ã‚¤ãƒ«ã—ã‹ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ããªã„ã‚ˆã†ã«ãªã£ã¦ã„ã¾ã™ã€‚
![[ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ 2025-08-02 23.09.26.png]]
Fig. 14: [Pattern Finderæ©Ÿèƒ½ã§Upload Text Filesã‚’é¸æŠã—ãŸå ´åˆã®åˆæœŸç”»é¢]

ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€Fig. 15ã®ã‚ˆã†ã«ã€Upload Filesã®ä¸­ã§ã€å…¥åŠ›ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã®å†…å®¹ã‚’ç¢ºèªã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ãƒ¬ãƒ™ãƒ«ã‚’é¸æŠã—ã€Processãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ã‹ã‚‰ã®ç”»é¢ã¯ã€ŒManual Text Inputã€ã‚’é¸æŠã—ãŸå ´åˆã¨åŒæ§˜ã«ãªã‚Šã¾ã™ã€‚
![[ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ 2025-08-02 23.27.28.png]]
Fig. 15: [Pattern Finderæ©Ÿèƒ½ã§ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸéš›ã®ç”»é¢]
### å·¥å¤«ç‚¹
#### 1. ãƒ‡ãƒ¥ã‚¢ãƒ«å…¥åŠ›ã‚·ã‚¹ãƒ†ãƒ 
- **Textbox Input**: å‹•çš„ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢è¿½åŠ /å‰Šé™¤æ©Ÿèƒ½
- **File Upload**: ãƒ‰ãƒ©ãƒƒã‚°&ãƒ‰ãƒ­ãƒƒãƒ— + ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠã®äºŒé‡ã‚µãƒãƒ¼ãƒˆ
##### ç›®çš„
**ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹å…¥åŠ›æ–¹å¼**
- ä¸€èˆ¬çš„ãªè‹±èªå­¦ç¿’è€…ã¯ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã§æ‰€æŒã—ã¦ã„ã‚‹ã‚±ãƒ¼ã‚¹ã¯å°‘ãªãã€ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã‚’ã—ãŸã„è‹±æ–‡ã‚’è¦‹ã¤ã‘ãŸã‚‰ã™ãã‚³ãƒ”ãƒ¼ï¼†ãƒšãƒ¼ã‚¹ãƒˆã§åˆ†æã‚’å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«ã—ãŸã„
- ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ³å¯¾å¿œã‚‚ã—ã¦ã„ã‚‹ãŸã‚ã€ã“ã®å ´åˆã‚‚ã“ã¡ã‚‰ã®æ–¹å¼ãŒé©åˆ‡ã§ã‚ã‚‹ã¨åˆ¤æ–­
	-> ä¸€èˆ¬çš„ãªè‹±èªå­¦ç¿’è€…ã«ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚ˆã‚Šã“ã¡ã‚‰ã®æ–¹å¼ãŒé©åˆ‡ã§ã‚ã‚‹ã¨åˆ¤æ–­ã—ã¾ã—ãŸ

**ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ–¹å¼**
- NLPå­¦ç¿’è€…ã¯ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã§ä¿æŒã—ã¦ã„ã‚‹ã“ã¨ãŒä¸€èˆ¬çš„ã§ã‚ã‚‹ãŸã‚ã€ã“ã¡ã‚‰ã®æ–¹å¼ãŒé©åˆ‡ã§ã‚ã‚‹ã¨åˆ¤æ–­ã—ã¾ã—ãŸ
- åˆ†æã‚’ä½•å›ã‚‚ç¹°ã‚Šè¿”ã™ã“ã¨ã‚’è€ƒãˆã¦ã‚‚ã€ã“ã¡ã‚‰ãŒé©åˆ‡ã§ã‚ã‚‹ã¨åˆ¤æ–­ã—ã¾ã—ãŸ

ä»¥ä¸Šã‚ˆã‚Šã€ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸ãˆã‚‹ã ã‘ã§ã‚‚ã€äºŒã¤ã®éœ€è¦ãŒã‚ã‚‹ã“ã¨ã‹ã‚‰ã€äºŒã¤ã®æ–¹å¼ã‚’å–ã‚‹ã“ã¨ã¯å¿…é ˆã§ã‚ã‚‹ã¨è€ƒãˆã¾ã—ãŸ
#### 2. ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ™‚ã®åˆ†æå¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆè¡¨ç¤º
ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã§å…¥åŠ›ã™ã‚‹éš›ã¯ã€ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’ç¢ºèªã™ã‚Œã°åˆ†æå¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¢ºèªã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ãŒã€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã®å ´åˆã¯ç¢ºèªã™ã‚‹ã“ã¨ãŒã§ãã¾ã›ã‚“ã§ã—ãŸã€‚åˆ†æå¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆã¨å‡ºåŠ›çµæœã‚’æ¯”è¼ƒã™ã‚‹ã“ã¨ãŒé‡è¦ã§ã‚ã‚‹ãŸã‚ã€ã“ã®æ©Ÿèƒ½ã‚’è¿½åŠ ã—ã¾ã—ãŸã€‚
ã¾ãŸã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ãªå®Ÿè£…ã«ã™ã‚‹ãŸã‚ã€Fig. 16ã®ã‚ˆã†ã«ã€åˆ†æå¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆã®é•·ã•ã«åˆã‚ã›ã¦è¡¨ç¤ºæ ãŒå¤‰å‹•ã™ã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã¾ã™ã€‚
![[ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ 2025-08-02 23.33.05.png]]
Fig. 16: [Pattern Finderæ©Ÿèƒ½ã§åˆ†æå¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¢ºèªã™ã‚‹ç”»é¢1]

ã¾ãŸã€æ–‡ç« ãŒé•·ã™ããŸã‚Šã€ã‚¹ãƒãƒ›ã§è¦‹ã‚‹å ´åˆã¯ã€Fig. 17ã®ã‚ˆã†ã«ä¸€å®šã®è¡Œæ•°ã‚’è¶…ãˆã‚‹ã¨ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ãŒã§ãæµã‚ˆã†ã«ãªã‚Šã€å¿…è¦ä»¥ä¸Šã«è¡¨ç¤ºè¡Œæ•°ã‚’å¢—ã‚„ã•ãªã„å·¥å¤«ã‚’ã—ã¦ã„ã¾ã™ã€‚
![[ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ 2025-08-02 23.53.19.png|400]]
Fig. 17: [Pattern Finderæ©Ÿèƒ½ã§åˆ†æå¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¢ºèªã™ã‚‹ç”»é¢2]

# Software evaluation

## Usability study
### Describe advice received in green task
7æœˆ15æ—¥(ç«)


### Accuracy evaluation
